{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# STTN Video Inpainting in Google Colab\n",
    "\n",
    "This notebook demonstrates how to run STTN (Spatial-Temporal Transformer Networks) for video inpainting in Google Colab.\n",
    "\n",
    "**Paper**: Learning Joint Spatial-Temporal Transformations for Video Inpainting (ECCV 2020)\n",
    "\n",
    "**Original Repository**: https://github.com/researchmm/STTN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## 1. Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_deps"
   },
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install torch>=1.8.0 torchvision>=0.9.0\n",
    "!pip install opencv-python==4.6.0.66\n",
    "!pip install Pillow>=8.0.0 numpy>=1.19.0 matplotlib>=3.3.0\n",
    "!pip install tqdm>=4.49.0 imageio>=2.8.0 scipy>=1.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "check_gpu"
   },
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "else:\n",
    "    print(\"No GPU available - will use CPU (very slow)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "upload"
   },
   "source": [
    "## 2. Upload Project Files\n",
    "\n",
    "Upload the STTN project folder to Colab, or clone from GitHub:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "clone_repo"
   },
   "outputs": [],
   "source": [
    "# Option 1: Clone from GitHub\n",
    "!git clone https://github.com/researchmm/STTN.git\n",
    "%cd STTN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "upload_files"
   },
   "outputs": [],
   "source": [
    "# Option 2: Upload files manually\n",
    "from google.colab import files\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Uncomment if you want to upload a zip file\n",
    "# uploaded = files.upload()\n",
    "# \n",
    "# # Extract the uploaded zip file\n",
    "# for filename in uploaded.keys():\n",
    "#     if filename.endswith('.zip'):\n",
    "#         with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
    "#             zip_ref.extractall('.')\n",
    "#         print(f\"Extracted {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "download_model"
   },
   "source": [
    "## 3. Download Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download_checkpoint"
   },
   "outputs": [],
   "source": [
    "# Create checkpoints directory\n",
    "!mkdir -p checkpoints\n",
    "\n",
    "# Download pretrained model (you may need to install gdown first)\n",
    "!pip install gdown\n",
    "!gdown 1ZAMV8547wmZylKRt5qR_tC5VlosXD4Wv -O checkpoints/sttn.pth\n",
    "\n",
    "# Verify the model file\n",
    "import os\n",
    "if os.path.exists('checkpoints/sttn.pth'):\n",
    "    size = os.path.getsize('checkpoints/sttn.pth') / (1024*1024)\n",
    "    print(f\"‚úì Model downloaded successfully! Size: {size:.1f} MB\")\n",
    "else:\n",
    "    print(\"‚úó Model download failed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_colab_script"
   },
   "source": [
    "## 4. Create Colab-Compatible Test Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_test_colab"
   },
   "outputs": [],
   "source": [
    "# Create the Colab-compatible test script\n",
    "test_colab_content = '''\n",
    "# -*- coding: utf-8 -*-\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import importlib\n",
    "import os\n",
    "import argparse\n",
    "import copy\n",
    "import datetime\n",
    "import random\n",
    "import sys\n",
    "import json\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "from torchvision import models\n",
    "import torch.multiprocessing as mp\n",
    "from torchvision import transforms\n",
    "\n",
    "# My libs\n",
    "from core.utils import Stack, ToTorchFormatTensor\n",
    "\n",
    "w, h = 432, 240\n",
    "ref_length = 10\n",
    "neighbor_stride = 5\n",
    "default_fps = 24\n",
    "\n",
    "_to_tensors = transforms.Compose([\n",
    "    Stack(),\n",
    "    ToTorchFormatTensor()])\n",
    "\n",
    "def get_ref_index(neighbor_ids, length):\n",
    "    ref_index = []\n",
    "    for i in range(0, length, ref_length):\n",
    "        if not i in neighbor_ids:\n",
    "            ref_index.append(i)\n",
    "    return ref_index\n",
    "\n",
    "def read_mask(mpath):\n",
    "    masks = []\n",
    "    mnames = os.listdir(mpath)\n",
    "    mnames.sort()\n",
    "    for m in mnames: \n",
    "        m = Image.open(os.path.join(mpath, m))\n",
    "        m = m.resize((w, h), Image.NEAREST)\n",
    "        m = np.array(m.convert('L'))\n",
    "        m = np.array(m > 0).astype(np.uint8)\n",
    "        m = cv2.dilate(m, cv2.getStructuringElement(\n",
    "            cv2.MORPH_CROSS, (3, 3)), iterations=4)\n",
    "        masks.append(Image.fromarray(m*255))\n",
    "    return masks\n",
    "\n",
    "def read_frame_from_videos(vname):\n",
    "    frames = []\n",
    "    vidcap = cv2.VideoCapture(vname)\n",
    "    success, image = vidcap.read()\n",
    "    count = 0\n",
    "    while success:\n",
    "        image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "        frames.append(image.resize((w,h)))\n",
    "        success, image = vidcap.read()\n",
    "        count += 1\n",
    "    return frames       \n",
    "\n",
    "def run_video_inpainting(video_path=\"examples/schoolgirls_orig.mp4\", \n",
    "                        mask_path=\"examples/schoolgirls\", \n",
    "                        ckpt_path=\"checkpoints/sttn.pth\",\n",
    "                        model_name=\"sttn\"):\n",
    "    \"\"\"\n",
    "    Main function for video inpainting - Colab friendly\n",
    "    \"\"\"\n",
    "    # Check if files exist\n",
    "    if not os.path.exists(video_path):\n",
    "        print(f\"Error: Video file {video_path} not found!\")\n",
    "        return None\n",
    "    if not os.path.exists(mask_path):\n",
    "        print(f\"Error: Mask directory {mask_path} not found!\")\n",
    "        return None\n",
    "    if not os.path.exists(ckpt_path):\n",
    "        print(f\"Error: Checkpoint file {ckpt_path} not found!\")\n",
    "        return None\n",
    "    \n",
    "    # set up models - Colab friendly device selection\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    net = importlib.import_module('model.' + model_name)\n",
    "    model = net.InpaintGenerator().to(device)\n",
    "    data = torch.load(ckpt_path, map_location=device)\n",
    "    model.load_state_dict(data['netG'])\n",
    "    print('Loading model from: {}'.format(ckpt_path))\n",
    "    model.eval()\n",
    "\n",
    "    # prepare dataset, encode all frames into deep space \n",
    "    frames = read_frame_from_videos(video_path)\n",
    "    video_length = len(frames)\n",
    "    print(f\"Video length: {video_length} frames\")\n",
    "    \n",
    "    feats = _to_tensors(frames).unsqueeze(0)*2-1\n",
    "    frames = [np.array(f).astype(np.uint8) for f in frames]\n",
    "\n",
    "    masks = read_mask(mask_path)\n",
    "    binary_masks = [np.expand_dims((np.array(m) != 0).astype(np.uint8), 2) for m in masks]\n",
    "    masks = _to_tensors(masks).unsqueeze(0)\n",
    "    feats, masks = feats.to(device), masks.to(device)\n",
    "    comp_frames = [None]*video_length\n",
    "\n",
    "    with torch.no_grad():\n",
    "        feats = model.encoder((feats*(1-masks).float()).view(video_length, 3, h, w))\n",
    "        _, c, feat_h, feat_w = feats.size()\n",
    "        feats = feats.view(1, video_length, c, feat_h, feat_w)\n",
    "    print('Loaded videos and masks')\n",
    "\n",
    "    # completing holes by spatial-temporal transformers\n",
    "    print(\"Processing frames...\")\n",
    "    for f in range(0, video_length, neighbor_stride):\n",
    "        neighbor_ids = [i for i in range(max(0, f-neighbor_stride), min(video_length, f+neighbor_stride+1))]\n",
    "        ref_ids = get_ref_index(neighbor_ids, video_length)\n",
    "        with torch.no_grad():\n",
    "            pred_feat = model.infer(\n",
    "                feats[0, neighbor_ids+ref_ids, :, :, :], masks[0, neighbor_ids+ref_ids, :, :, :])\n",
    "            pred_img = torch.tanh(model.decoder(\n",
    "                pred_feat[:len(neighbor_ids), :, :, :])).detach()\n",
    "            pred_img = (pred_img + 1) / 2\n",
    "            pred_img = pred_img.cpu().permute(0, 2, 3, 1).numpy()*255\n",
    "            for i in range(len(neighbor_ids)):\n",
    "                idx = neighbor_ids[i]\n",
    "                img = np.array(pred_img[i]).astype(\n",
    "                    np.uint8)*binary_masks[idx] + frames[idx] * (1-binary_masks[idx])\n",
    "                if comp_frames[idx] is None:\n",
    "                    comp_frames[idx] = img\n",
    "                else:\n",
    "                    comp_frames[idx] = comp_frames[idx].astype(\n",
    "                        np.float32)*0.5 + img.astype(np.float32)*0.5\n",
    "        \n",
    "        if (f // neighbor_stride) % 10 == 0:\n",
    "            print(f\"Processed {f + neighbor_stride}/{video_length} frames\")\n",
    "                        \n",
    "    # Generate output filename\n",
    "    output_filename = f\"{os.path.splitext(os.path.basename(video_path))[0]}_result.mp4\"\n",
    "    print(f\"Writing output video: {output_filename}\")\n",
    "    \n",
    "    writer = cv2.VideoWriter(output_filename, cv2.VideoWriter_fourcc(*\"mp4v\"), default_fps, (w, h))\n",
    "    for f in range(video_length):\n",
    "        comp = np.array(comp_frames[f]).astype(\n",
    "            np.uint8)*binary_masks[f] + frames[f] * (1-binary_masks[f])\n",
    "        writer.write(cv2.cvtColor(np.array(comp).astype(np.uint8), cv2.COLOR_RGB2BGR))\n",
    "    writer.release()\n",
    "    print('‚úì Video inpainting completed!')\n",
    "    print(f'Output saved as: {output_filename}')\n",
    "    return output_filename\n",
    "'''\n",
    "\n",
    "# Write the script to file\n",
    "with open('test_colab.py', 'w') as f:\n",
    "    f.write(test_colab_content)\n",
    "\n",
    "print(\"‚úì Created test_colab.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "run_example"
   },
   "source": [
    "## 5. Run Video Inpainting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "check_files"
   },
   "outputs": [],
   "source": [
    "# Check if example files exist\n",
    "import os\n",
    "\n",
    "required_files = [\n",
    "    \"examples/schoolgirls_orig.mp4\",\n",
    "    \"examples/schoolgirls\",\n",
    "    \"checkpoints/sttn.pth\"\n",
    "]\n",
    "\n",
    "print(\"Checking required files:\")\n",
    "all_exist = True\n",
    "for file in required_files:\n",
    "    exists = os.path.exists(file)\n",
    "    status = \"‚úì\" if exists else \"‚úó\"\n",
    "    print(f\"{status} {file}\")\n",
    "    if not exists:\n",
    "        all_exist = False\n",
    "\n",
    "if all_exist:\n",
    "    print(\"\\n‚úì All required files found!\")\n",
    "else:\n",
    "    print(\"\\n‚úó Some files are missing. Please upload them first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "run_inpainting"
   },
   "outputs": [],
   "source": [
    "# Run video inpainting\n",
    "from test_colab import run_video_inpainting\n",
    "\n",
    "# Run with default parameters (schoolgirls example)\n",
    "result = run_video_inpainting()\n",
    "\n",
    "if result:\n",
    "    print(f\"\\nüéâ Success! Output video: {result}\")\n",
    "    \n",
    "    # Display video info\n",
    "    import cv2\n",
    "    cap = cv2.VideoCapture(result)\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    cap.release()\n",
    "    \n",
    "    print(f\"Video info: {frame_count} frames, {fps} FPS, {width}x{height}\")\n",
    "else:\n",
    "    print(\"‚ùå Video inpainting failed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "custom_usage"
   },
   "source": [
    "## 6. Custom Usage\n",
    "\n",
    "You can also run with your own video and mask files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "upload_custom"
   },
   "outputs": [],
   "source": [
    "# Upload your own video and mask files\n",
    "from google.colab import files\n",
    "\n",
    "print(\"Upload your video file:\")\n",
    "uploaded_video = files.upload()\n",
    "\n",
    "print(\"\\nUpload your mask files (as a zip):\")\n",
    "uploaded_masks = files.upload()\n",
    "\n",
    "# Extract mask files if uploaded as zip\n",
    "import zipfile\n",
    "for filename in uploaded_masks.keys():\n",
    "    if filename.endswith('.zip'):\n",
    "        with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
    "            zip_ref.extractall('custom_masks')\n",
    "        print(f\"Extracted masks to custom_masks/\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "run_custom"
   },
   "outputs": [],
   "source": [
    "# Run with custom files\n",
    "# Adjust these paths based on your uploaded files\n",
    "custom_video = \"your_video.mp4\"  # Replace with your video filename\n",
    "custom_masks = \"custom_masks\"    # Replace with your mask folder\n",
    "\n",
    "result = run_video_inpainting(\n",
    "    video_path=custom_video,\n",
    "    mask_path=custom_masks,\n",
    "    ckpt_path=\"checkpoints/sttn.pth\"\n",
    ")\n",
    "\n",
    "if result:\n",
    "    print(f\"\\nüéâ Success! Custom output video: {result}\")\n",
    "else:\n",
    "    print(\"‚ùå Custom video inpainting failed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "download_results"
   },
   "source": [
    "## 7. Download Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download_output"
   },
   "outputs": [],
   "source": [
    "# Download the output video\n",
    "from google.colab import files\n",
    "import os\n",
    "\n",
    "# List all result videos\n",
    "result_files = [f for f in os.listdir('.') if f.endswith('_result.mp4')]\n",
    "\n",
    "print(\"Available result videos:\")\n",
    "for file in result_files:\n",
    "    size = os.path.getsize(file) / (1024*1024)\n",
    "    print(f\"  {file} ({size:.1f} MB)\")\n",
    "\n",
    "# Download all result videos\n",
    "for file in result_files:\n",
    "    print(f\"Downloading {file}...\")\n",
    "    files.download(file)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}